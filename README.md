# ğŸ­ pandas-manufacturing-downtime-analytics

A **Pandas-based manufacturing operations analytics** project focused on analyzing production throughput, downtime behavior, and operational inefficiencies in an industrial beverage bottling line.

The project follows a **layered and modular data pipeline architecture**, transforming raw event logs and time-series operational data into validated analytical features, operational KPIs, and interpretable performance insights.

Unlike traditional business analytics projects, this project operates on **event-level production logs and multi-resolution time-series data**, aiming to understand *where, when, and how production time is lost inside a real manufacturing process*.

This project answers questions such as:

- Where does downtime concentrate across the production timeline?
- Which hours and operating windows suffer the highest inefficiencies?
- How do micro-level downtime events propagate into hourly and daily performance losses?
- How consistent are operational metrics across multiple aggregation layers?

---

## ğŸ“Œ Project Overview

Operational efficiency in manufacturing cannot be understood only through daily summaries or total production numbers.  
True optimization requires analyzing how machines behave at the event level and validating how those behaviors aggregate into hourly and daily operational performance.

This project focuses on:

- Event-level downtime intelligence  
- Hourly throughput and efficiency behavior  
- Daily operational stability and performance validation  
- Cross-table consistency checks between raw logs and aggregated datasets  

The project provides:

- A multi-stage data pipeline (`raw â†’ cleaned â†’ featured â†’ analytics`)
- Event sessionization and downtime duration engineering
- Multi-resolution time-series validation (event â†’ hour â†’ day)
- Throughput vs downtime correlation analysis
- Operational efficiency and loss pattern detection
- Static visualizations and optional dashboards

---

## ğŸ“Š Dataset

[**Industrial Production - Beverage Bottling Line**](https://www.kaggle.com/datasets/gabrielaugustodavid/industrial-production-beverage-bottling-line)  


The dataset contains four complementary tables representing different aggregation layers of the same production system.

### Tables

- **downtime_event_log.csv**  
  Event-level downtime logs including start time, end time, and recorded downtime duration.

- **hourly_operation_breakdown.csv**  
  Hourly operational metrics including monitored time, operation time, downtime, and efficiency.

- **processed_hourly.csv**  
  Hourly production throughput measured in gallons.

- **daily_operation_summary.csv**  
  Daily production summaries including efficiency, operation time, pause time, and production volume.

**Data organization:**
- Raw data: `data/raw`
- Cleaned data: `data/cleaned`
- Feature-engineered data: `data/featured`

---

## ğŸ“ˆ Example Outputs

### â±ï¸ Downtime Intelligence
- Downtime event duration distribution  
- Downtime clustering and burst detection  
- Hourly downtime density heatmap  
- Validation of recorded downtime vs computed durations  
- Recovery time analysis  

![](outputs/figures/downtime_event_distribution.png)  
![](outputs/figures/downtime_density_heatmap.png)

---

### âš™ï¸ Hourly Performance Analysis
- Production throughput vs downtime correlation  
- Zero-production window detection  
- Hourly efficiency decay patterns  
- Throughput volatility analysis  
- Cross-table validation against hourly operational summaries  

![](outputs/figures/hourly_efficiency_trend.png)  
![](outputs/figures/throughput_vs_downtime.png)

---

### ğŸ“† Daily Operational Stability
- Daily efficiency trend analysis  
- Pause ratio distribution  
- Best vs worst operational days  
- Stability and variance analysis  
- Product-level performance comparison  

![](outputs/figures/daily_efficiency_trend.png)  
![](outputs/figures/pause_ratio_distribution.png)

---

### ğŸ” Cross-Level Consistency Validation
- Event-level vs hourly downtime reconciliation  
- Hourly vs daily aggregation consistency  
- Outlier detection and anomaly flagging  
- Data quality validation reports  

![](outputs/figures/consistency_validation.png)

---

### ğŸŒ Interactive Dashboard

- Interactive Dashboard Demo  
![](docs/demo.gif)

ğŸ–±ï¸ **Live Dashboard:**  
<a href="https://busracevik.github.io/pandas-manufacturing-downtime-analytics/index.html" target="_blank">View Interactive Dashboard</a>

---


## ğŸ” Key Insight Example

Operational losses are not evenly distributed across the production timeline.  
A small number of clustered downtime windows account for a disproportionate share of total lost production time, confirming a Pareto-like behavior in operational inefficiencies.

Cross-validation between event logs and hourly summaries reveals minor aggregation gaps, highlighting the importance of validation layers in real-world industrial data pipelines.

---

## ğŸ“ Project Structure

```text
pandas-manufacturing-downtime-analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â””â”€â”€ featured/
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ tables/
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ demo.gif
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ event_analysis.py
â”‚   â”‚   â”œâ”€â”€ hourly_analysis.py
â”‚   â”‚   â””â”€â”€ daily_analysis.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ plots.py
â”‚       â””â”€â”€ dashboard.py
â”‚
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```
## ğŸ›  Technologies Used

- **Python** â€“ Core programming language  
- **Pandas** â€“ Data preprocessing and analytics  
- **NumPy** â€“ Numerical computations  
- **Matplotlib** â€“ Static visualizations  
- **Plotly** â€“ Interactive dashboards  

---

## ğŸ§  Analytical Approach

This project emphasizes **operational interpretability and process understanding** rather than predictive modeling.

No machine learning models are used.

Instead, the analysis relies on:

- Event-level time reconstruction  
- Time-based aggregation and validation  
- Throughput and downtime correlation analysis  
- Multi-resolution consistency checks  

The focus is on explaining **where operational losses occur and how they propagate through the production timeline**.

---

## ğŸ“ Core Metrics & Definitions

### â±ï¸ Downtime Duration

**Definition:**

$$
\text{Downtime Duration} = \text{Downtime End Time} - \text{Downtime Start Time}
$$

**Explanation:**  
Represents the length of each downtime event.

---

### â³ Hourly Downtime Ratio

**Definition:**

$$
\text{Downtime Ratio}_{hour} = \frac{\text{Downtime}_h}{\text{Monitored Time}_h}
$$

**Explanation:**  
Measures the proportion of lost production time per hour.

---

### âš™ï¸ Throughput

**Definition:**

$$
\text{Throughput} = \frac{\text{Total Production Volume}}{\text{Operation Time}}
$$

**Explanation:**  
Measures production efficiency over time.

---

### ğŸ“Š Daily Efficiency

**Definition:**

$$
\text{Efficiency}_{day} = \frac{\text{Operation Time}}{\text{Monitored Time}}
$$

**Explanation:**  
Represents overall daily operational utilization.

